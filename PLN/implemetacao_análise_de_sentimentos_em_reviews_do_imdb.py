# -*- coding: utf-8 -*-
"""Cópia de Análise de Sentimentos em Reviews do IMDb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tnfXQCCLpzSjfyi3NbDWtfUqirJTtWT2

**Identificação do aluno**

**Email:** Lucas de Lima da Silva

**Matrícula:** 121110517

# Análise de Sentimentos em Reviews do IMDb

O principal objetivo desta tarefa é aplicar três modelos de aprendizado de máquina distintos - Regressão Linear, Naive Bayes e Perceptron - para realizar a análise de sentimento em um conjunto de dados de *reviews* de usuários sobre filmes no IMDb. Ao final desta tarefa, você deverá ter uma compreensão mais profunda de como esses modelos funcionam, suas vantagens e limitações quando aplicados a dados textuais do mundo real. Este conjunto de dados inclui avaliações de texto juntamente com rótulos de sentimento correspondentes (positivo ou negativo) para a aprendizagem supervisionada.

## Bibliotecas
"""

# Para a leitura dos dados
import pandas as pd

# Manipulação de texto
import nltk.corpus
from nltk                             import SnowballStemmer
from nltk.tokenize                    import word_tokenize

nltk.download('stopwords')
nltk.download('punkt')

# Prepraração dos dados
from sklearn.feature_extraction.text  import TfidfVectorizer
from sklearn.model_selection          import train_test_split

# Modelos de classificação
from sklearn.linear_model import LogisticRegression, Perceptron
from sklearn.naive_bayes import MultinomialNB

# Avaliação
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

import seaborn as sns
import numpy as np

"""## Leitura dos dados"""

df = pd.read_csv('https://gist.githubusercontent.com/issilva5/44c9406a85b0fed0d62668752cc31b09/raw/49e01d2e8011bdd83d0bc835a518e398ae319303/movie_reviews.csv')
df.head()

"""Os dados estão distribuídos em duas classes:"""

df.groupby('sentiment').count()

"""A seguir criaremos uma lista com o texto."""

corpus = df['content'].tolist()

"""## Limpeza dos dados

Antes de aplicar modelos de aprendizado de máquina, você precisará limpar e pré-processar os dados textuais. É esperado que você aplique pelo menos as seguintes tarefas de limpeza dos dados:

- Tokenização
- Remoção de palavras muito pequenas (<= 2) ou muito grandes (>= 15).
- Remoção de stopwords.
- Stemming.
"""

from nltk.corpus import stopwords
from nltk import word_tokenize, SnowballStemmer

  # Implemente uma função que recebe uma lista de tokens
  # e retorna uma lista sem os tokens muito pequenos (<= 2)
  # ou muito grandes (> 15).
def remove_palavras_pequenas_grandes(tokens):
  return [token for token in tokens if 2 < len(token) <= 15]
  pass

# Implemente uma função que recebe uma lista de tokens
# e retorna uma lista sem stopwords.
def remove_stopwords(tokens):
  stop_words = set(stopwords.words('english'))
  return [token for token in tokens if token.lower() not in stop_words]
  pass

# Implemente uma função que recebe uma lista de tokens
# e retorna uma lista com os tokens stemmizados.
def stemming(tokens):
  stemmer = SnowballStemmer('english')
  return [stemmer.stem(token) for token in tokens]
  pass

def process_corpus(corpus):
  corpus_processed = []
  for document in corpus:
    tokens = word_tokenize(document)
    tokens = remove_palavras_pequenas_grandes(tokens)
    tokens = remove_stopwords(tokens)
    tokens = stemming(tokens)
    corpus_processed.append(" ".join(tokens))
  return corpus_processed

corpus_processed = process_corpus(corpus)

print("Texto bruto: \n" + corpus[1262])
print("\nTexto Processado: \n" + corpus_processed[1262])

"""## Preparando os dados para os modelos

Primeiramente, realize a vetorização TF-IDF dos dados.
"""

# Você deve instanciar um vetorizador TF-IDF e aplicá-lo ao corpus processado.

vectorizer = TfidfVectorizer()

x = vectorizer.fit_transform(corpus_processed)

y = df['sentiment'].to_numpy()

"""Agora, realize a partição treino e teste dos dados."""

# Você deve realizar a partição treino e teste dos dados aqui.

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=42)
print("Dimensão do conjunto de treino:", x_train.shape, y_train.shape)
print("Dimensão do conjunto de teste:", x_test.shape, y_test.shape)

"""## Treinando modelos

Finalmente, instancie e treine os três modelos (Regressão Logística, Naive Bayes e Perceptron).
"""

# Você deve instanciar e treinar os três modelos de Regressão Logística
model_1 = LogisticRegression(random_state=0).fit(x_train, y_train)
model_2 = MultinomialNB().fit(x_train, y_train)
model_3 = Perceptron(random_state=0, max_iter=300).fit(x_train, y_train)

"""## Avaliação dos modelos

Você deve realizar as predições para cada um dos três modelos.
"""

# Realize as predições para cada um dos modelos
model_1.predict(x_test)[:20]

model_2.predict(x_test)[:20]

model_3.predict(x_test)[:20]

model_1.classes_

model_1.predict_proba(x_test)[:20]

model_2.predict_proba(x_test)[:20]

model_3.decision_function(x_test)[:20]

"""Plote a matriz de confusão para cada modelo."""

def plot_confusion_matrix(y_test, y_pred, labels, title):
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(f'Matriz de Confusão - {title}')
    plt.xlabel('Classe Predita')
    plt.ylabel('Classe Verdadeira')
    plt.show()

labels = ['Negative', 'Positive'] if set(np.unique(y_test)) == {0, 1} else np.unique(y_test)

plot_confusion_matrix(y_test, model_1.predict(x_test), labels, 'Regressão Logística')

plot_confusion_matrix(y_test, model_2.predict(x_test), labels, 'Regressão Naive Bayes Multinomial')

plot_confusion_matrix(y_test, model_3.predict(x_test), labels, 'Perceptron')

"""Calcule métricas (acurácia, recall, precision, f1-score) para cada uma das predições."""

# Para cada um dos modelos produza as métricas pedidas.

print("Model 1: \n" + classification_report(y_test, model_1.predict(x_test)) + "-"*60 + "\n")

print("Model 2: \n" + classification_report(y_test, model_2.predict(x_test)) + "-"*60 + "\n")

print("Model 3: \n" + classification_report(y_test, model_3.predict(x_test)) + "-"*60 + "\n")

"""#### Perguntas

***Discuta sobre os resultados do modelo considerando as matrizes de confusão e as métricas calculadas.***

Com base nas matrizes de confusão e nas métricas calculadas (acurácia, recall, precision, f1-score) para cada modelo, podemos fazer as seguintes observações:

1. Regressão Logística (Model 1)
Matriz de Confusão:
O modelo classificou corretamente 87% dos exemplos negativos e 90% dos exemplos positivos.
Há uma leve tendência de o modelo ser mais preciso ao classificar exemplos positivos.
Métricas:
Acurácia: 0.88 (alta, indicando um bom desempenho global).
Precision e Recall: Ambos são equilibrados para as classes negativas e positivas, com valores em torno de 0.88.
F1-Score: Também alto, refletindo um bom equilíbrio entre precision e recall.

2. Naive Bayes Multinomial (Model 2)
Matriz de Confusão:
O modelo classificou corretamente 87% dos exemplos negativos e 85% dos exemplos positivos.
O desempenho é ligeiramente melhor para a classe negativa em comparação com a classe positiva.
Métricas:
Acurácia: 0.86 (ligeiramente inferior à da regressão logística).
Precision: Levemente maior para a classe positiva.
Recall: Levemente maior para a classe negativa.
F1-Score: Reflete um desempenho equilibrado, mas um pouco inferior ao modelo de regressão logística.

3. Perceptron (Model 3)
Matriz de Confusão:
O modelo teve um desempenho equilibrado entre as classes, com 86% de acurácia para ambas as classes.
Métricas:
Acurácia: 0.86 (igual ao Naive Bayes).
Precision e Recall: Muito próximos, indicando que o modelo tem um desempenho uniforme para ambas as classes.
F1-Score: Igualmente equilibrado para ambas as classes, mas um pouco inferior ao da regressão logística.
Conclusões
Desempenho Global: A regressão logística apresentou o melhor desempenho geral, com a maior acurácia e valores ligeiramente superiores de precision, recall e f1-score.

Equilíbrio entre Classes: Todos os modelos mostraram um bom equilíbrio entre as classes "neg" e "pos", o que é importante em problemas de classificação binária, onde um viés para uma classe pode ser prejudicial.

Aplicabilidade: Dependendo do contexto, se um modelo mais simples e interpretável for desejado, o Naive Bayes pode ser uma boa escolha, especialmente se o desempenho ligeiramente inferior for aceitável. No entanto, para maximizar a performance, a regressão logística parece ser a melhor opção.

## Interpretando os modelos

Uma subárea importante da aprendizagem de máquina é a interpretação dos modelos.

Nesta parte do laboratório, você deve implementar funções para facilitar a interpretação dos modelos treinados e responder algumas perguntas sobre eles.

### Implementando funções auxiliares

A seguir é pedido que você implemente duas funções.

A primeira delas **recupera_palavras_positivas** deve retornar as top-20 palavras que mais contribuem para a classificação do texto como positivo. A segunda **recupera_palavras_negativas** deve fazer o equivalente para a classificação negativa.

Os modelos de Regressão Logística e Perceptron tem um parâmetro chamado ***coef_*** este parâmetro retorna o peso de cada feature (palavra) tem no modelo. Palavras com peso positivo influenciam para a classificação positiva, e palavras com peso negativo fazem o inverso. O valor desse parâmetro tem a dimensão (1, n_features).

Já o modelo Naive Bayes tem um parâmetro chamado ***feature_log_prob_***. Este parâmetro retorna o log das probabilidades de cada palavra aparecer no texto dada uma classe. O valor desse parâmetro tem a dimensão (2, n_features), de modo que a posição 0 corresponde as probabilidades para a classe negativa e a posição para a classe positiva. Quanto maior for a probabilidade de uma palavra, maior podemos dizer que é sua influência na classificação.

Para acessar o nomes das features em ordem utilize o método **get_feature_names_out** do vetorizador construído.

Ambas as funções devem retornar uma lista de tuplas (string, float), ou seja, (palavra, peso).
"""

def recupera_palavras_positivas(modelo, vectorizer, top_n=20):
  feature_names = vectorizer.get_feature_names_out()
  n_features = len(feature_names)

  top_n = min(top_n, n_features)

  if hasattr(modelo, 'coef_'):
    coef = modelo.coef_[0]
  elif hasattr(modelo, 'feature_log_prob_'):
    coef = modelo.feature_log_prob_[1]

  top_indices = np.argsort(coef)[-top_n:]
  palavras_positivas = [(feature_names[i], coef[i]) for i in reversed(top_indices)]

  return palavras_positivas

def recupera_palavras_negativas(modelo, vectorizer, top_n=20):
  feature_names = vectorizer.get_feature_names_out()
  n_features = len(feature_names)

  top_n = min(top_n, n_features)

  if hasattr(modelo, 'coef_'):
    coef = modelo.coef_[0]
  elif hasattr(modelo, 'feature_log_prob_'):
    coef = modelo.feature_log_prob_[0]

  top_indices = np.argsort(coef)[:top_n]
  palavras_negativas = [(feature_names[i], coef[i]) for i in top_indices]

  return palavras_negativas

"""### Visualizando e interpretando

Use a função abaixo para visualizar uma nuvem de palavras do retorno das funções.
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud

def plot_wordcloud(lista_de_tuplas):
    # Cria um dicionário a partir da lista de tuplas
    palavra_freq = {t[0]: t[1] for t in lista_de_tuplas}

    # Cria a WordCloud
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(palavra_freq)

    # Plota a WordCloud
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.show()

"""#### Palavras positivas"""

# Plote aqui a nuvem de palavras para a Regressão Logística
palavras_positivas_logistica_modelo_1 = recupera_palavras_positivas(model_1, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_1)

# Plote aqui a nuvem de palavras para o Naive Bayes
palavras_positivas_logistica_modelo_2 = recupera_palavras_positivas(model_2, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_2)

# Plote aqui a nuvem de palavras para o Perceptron
palavras_positivas_logistica_modelo_3 = recupera_palavras_positivas(model_3, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_3)

"""#### Palavras negativas"""

# Plote aqui a nuvem de palavras para a Regressão Logística
palavras_positivas_logistica_modelo_1 = recupera_palavras_negativas(model_1, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_1)

# Plote aqui a nuvem de palavras para o Naive Bayes
palavras_positivas_logistica_modelo_2 = recupera_palavras_negativas(model_2, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_2)

# Plote aqui a nuvem de palavras para o Perceptron
palavras_positivas_logistica_modelo_3 = recupera_palavras_negativas(model_3, vectorizer)
plot_wordcloud(palavras_positivas_logistica_modelo_3)

"""#### Perguntas

**1. Analisando as nuvens de palavras positivas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento positivo? Dê exemplos.**

Sim.

Exemplos:

Model_1: perfect e favorit

Model_2: like e good

Model_3: brilliant e definit

**2. Analisando as nuvens de palavras negativas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento negativo? Dê exemplos.**

Sim.

Exemplos:

Model_1: horribl e stupid

Model_2: pseudohappi e pseudointens

Model_3: embarrass e unfunni

**3. Considerando as métricas calculadas e a análise acima, qual modelo você acredita ser o melhor na tarefa? Por quê?**

Considerando as métricas de desempenho e a análise das nuvens de palavras, o Model 1 (Regressão Logística) é o melhor modelo para esta tarefa. Ele não apenas apresentou as melhores métricas de desempenho, com a maior acurácia e valores equilibrados de precision e recall, mas também capturou palavras altamente representativas tanto de sentimentos positivos quanto negativos.

## Testando mais modelos

Até então no exerício utilizamos três modelos de classificação, entretanto existem muitos outros disponíveis no sklearn. Escolha um dos três modelos para treinar e avaliar nos dados. Em seguida compare os resultados com os modelos anteriores.

- [Nearest Neighbors Classification](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)
- [Decision Tree](https://scikit-learn.org/stable/modules/tree.html#classification)
- [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html#classification)
"""

# Importe o modelo que será utilizado
from sklearn.tree import DecisionTreeClassifier

# Treine aqui o modelo escolhido
model_4 = DecisionTreeClassifier(random_state=42)
model_4.fit(x_train, y_train)

# Faça a previsão dos resultados
y_pred_tree = model_4.predict(x_test)

# Avalie o modelo usando a matriz de confusão e as métricas anteriores
plot_confusion_matrix(y_test, y_pred_tree, labels, 'Decision Tree')

print("Decision Tree: \n" + classification_report(y_test, y_pred_tree) + "-"*60 + "\n")

"""### Perguntas

**1. Explique brevemente como o modelo que você escolheu funciona (a documentação do sklearn pode servir de fonte para esta resposta).**

O modelo Decision Tree (Árvore de Decisão) é um método de classificação que segmenta os dados em subconjuntos mais homogêneos, de acordo com valores de diferentes features. A árvore é composta de nós, onde cada nó interno representa uma condição em uma feature (por exemplo, se um valor é maior ou menor do que um limiar), e as folhas representam a classe de saída (ou decisão).

**2. Como foi o desempenho do modelo escolhido em relação aos demais modelos?**

O desempenho do Decision Tree foi inferior em comparação aos outros modelos, como Regressão Logística, Naive Bayes, e Perceptron. Enquanto os outros modelos alcançaram uma acurácia em torno de 86% a 88%, o Decision Tree apresentou uma acurácia de 71%. Além disso, as métricas de precisão, recall e F1-score também foram mais baixas para o Decision Tree. Isso pode indicar que o modelo de árvore de decisão teve dificuldades em capturar as nuances dos dados, talvez devido à falta de generalização (overfitting) ou à incapacidade de encontrar boas divisões nas features usadas.
"""