# -*- coding: utf-8 -*-
"""Análise de Sentimentos em Reviews do IMDb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17vin0OboKLssCoA1h7faf4LAr6npANAQ

**Identificação do aluno**

**Email:**

**Matrícula:**

# Análise de Sentimentos em Reviews do IMDb

O principal objetivo desta tarefa é aplicar três modelos de aprendizado de máquina distintos - Regressão Linear, Naive Bayes e Perceptron - para realizar a análise de sentimento em um conjunto de dados de *reviews* de usuários sobre filmes no IMDb. Ao final desta tarefa, você deverá ter uma compreensão mais profunda de como esses modelos funcionam, suas vantagens e limitações quando aplicados a dados textuais do mundo real. Este conjunto de dados inclui avaliações de texto juntamente com rótulos de sentimento correspondentes (positivo ou negativo) para a aprendizagem supervisionada.

## Bibliotecas
"""

# Para a leitura dos dados
import pandas as pd

# Manipulação de texto
import nltk.corpus
from nltk                             import SnowballStemmer
from nltk.tokenize                    import word_tokenize

nltk.download('stopwords')
nltk.download('punkt')

# Prepraração dos dados
from sklearn.feature_extraction.text  import TfidfVectorizer
from sklearn.model_selection          import train_test_split

# Modelos de classificação
from sklearn.linear_model import LogisticRegression, Perceptron
from sklearn.naive_bayes import MultinomialNB

# Avaliação
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

"""## Leitura dos dados"""

df = pd.read_csv('https://gist.githubusercontent.com/issilva5/44c9406a85b0fed0d62668752cc31b09/raw/49e01d2e8011bdd83d0bc835a518e398ae319303/movie_reviews.csv')
df.head()

"""Os dados estão distribuídos em duas classes:"""

df.groupby('sentiment').count()

"""A seguir criaremos uma lista com o texto."""

corpus = df['content'].tolist()

"""## Limpeza dos dados

Antes de aplicar modelos de aprendizado de máquina, você precisará limpar e pré-processar os dados textuais. É esperado que você aplique pelo menos as seguintes tarefas de limpeza dos dados:

- Tokenização
- Remoção de palavras muito pequenas (<= 2) ou muito grandes (>= 15).
- Remoção de stopwords.
- Stemming.
"""

def remove_palavras_pequenas_grandes(tokens):
  # Implemente uma função que recebe uma lista de tokens
  # e retorna uma lista sem os tokens muito pequenos (<= 2)
  # ou muito grandes (> 15).
  pass

def remove_stopwords(tokens):
  # Implemente uma função que recebe uma lista de tokens
  # e retorna uma lista sem stopwords.
  pass

def stemming(tokens):
  # Implemente uma função que recebe uma lista de tokens
  # e retorna uma lista com os tokens stemmizados.
  pass

def process_corpus(corpus):
  corpus_processed = []
  for document in corpus:
    tokens = word_tokenize(document)
    tokens = remove_palavras_pequenas_grandes(tokens)
    tokens = remove_stopwords(tokens)
    tokens = stemming(tokens)
    corpus_processed.append(" ".join(tokens))
  return corpus_processed

corpus_processed = process_corpus(corpus)

"""## Preparando os dados para os modelos

Primeiramente, realize a vetorização TF-IDF dos dados.
"""

# Você deve instanciar um vetorizador TF-IDF e aplicá-lo ao corpus processado.

"""Agora, realize a partição treino e teste dos dados."""

# Você deve realizar a partição treino e teste dos dados aqui.

"""## Treinando modelos

Finalmente, instancie e treine os três modelos (Regressão Logística, Naive Bayes e Perceptron).
"""

# Você deve instanciar e treinar os três modelos de Regressão Logística

"""## Avaliação dos modelos

Você deve realizar as predições para cada um dos três modelos.
"""

# Realize as predições para cada um dos modelos

"""Plote a matriz de confusão para cada modelo."""

# Faça o plot da matriz de confusão de contagem para cada um dos modelos.

"""Calcule métricas (acurácia, recall, precision, f1-score) para cada uma das predições."""

# Para cada um dos modelos produza as métricas pedidas.

"""#### Perguntas

***Discuta sobre os resultados do modelo considerando as matrizes de confusão e as métricas calculadas.***

*Discussão.*

## Interpretando os modelos

Uma subárea importante da aprendizagem de máquina é a interpretação dos modelos.

Nesta parte do laboratório, você deve implementar funções para facilitar a interpretação dos modelos treinados e responder algumas perguntas sobre eles.

### Implementando funções auxiliares

A seguir é pedido que você implemente duas funções.

A primeira delas **recupera_palavras_positivas** deve retornar as top-20 palavras que mais contribuem para a classificação do texto como positivo. A segunda **recupera_palavras_negativas** deve fazer o equivalente para a classificação negativa.

Os modelos de Regressão Logística e Perceptron tem um parâmetro chamado ***coef_*** este parâmetro retorna o peso de cada feature (palavra) tem no modelo. Palavras com peso positivo influenciam para a classificação positiva, e palavras com peso negativo fazem o inverso. O valor desse parâmetro tem a dimensão (1, n_features).

Já o modelo Naive Bayes tem um parâmetro chamado ***feature_log_prob_***. Este parâmetro retorna o log das probabilidades de cada palavra aparecer no texto dada uma classe. O valor desse parâmetro tem a dimensão (2, n_features), de modo que a posição 0 corresponde as probabilidades para a classe negativa e a posição para a classe positiva. Quanto maior for a probabilidade de uma palavra, maior podemos dizer que é sua influência na classificação.

Para acessar o nomes das features em ordem utilize o método **get_feature_names_out** do vetorizador construído.

Ambas as funções devem retornar uma lista de tuplas (string, float), ou seja, (palavra, peso).
"""

def recupera_palavras_positivas(modelo):
  pass

def recupera_palavras_negativas(modelo):
  pass

"""### Visualizando e interpretando

Use a função abaixo para visualizar uma nuvem de palavras do retorno das funções.
"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud

def plot_wordcloud(lista_de_tuplas):
    # Cria um dicionário a partir da lista de tuplas
    palavra_freq = {t[0]: t[1] for t in lista_de_tuplas}

    # Cria a WordCloud
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(palavra_freq)

    # Plota a WordCloud
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.show()

"""#### Palavras positivas"""

# Plote aqui a nuvem de palavras para a Regressão Logística

# Plote aqui a nuvem de palavras para o Naive Bayes

# Plote aqui a nuvem de palavras para o Perceptron

"""#### Palavras negativas"""

# Plote aqui a nuvem de palavras para a Regressão Logística

# Plote aqui a nuvem de palavras para o Naive Bayes

# Plote aqui a nuvem de palavras para o Perceptron

"""#### Perguntas

**1. Analisando as nuvens de palavras positivas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento positivo? Dê exemplos.**

*Resposta.*

**2. Analisando as nuvens de palavras negativas de cada modelo, é possível identificar que as palavras estão associadas à um sentimento negativo? Dê exemplos.**

*Resposta.*

**3. Considerando as métricas calculadas e a análise acima, qual modelo você acredita ser o melhor na tarefa? Por quê?**

*Resposta.*

## Testando mais modelos

Até então no exerício utilizamos três modelos de classificação, entretanto existem muitos outros disponíveis no sklearn. Escolha um dos três modelos para treinar e avaliar nos dados. Em seguida compare os resultados com os modelos anteriores.

- [Nearest Neighbors Classification](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)
- [Decision Tree](https://scikit-learn.org/stable/modules/tree.html#classification)
- [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html#classification)
"""

# Importe o modelo que será utilizado

# Treine aqui o modelo escolhido

# Faça a previsão dos resultados

# Avalie o modelo usando a matriz de confusão e as métricas anteriores

"""### Perguntas

**1. Explique brevemente como o modelo que você escolheu funciona (a documentação do sklearn pode servir de fonte para esta resposta).**

*Resposta*

**2. Como foi o desempenho do modelo escolhido em relação aos demais modelos?**

*Resposta*
"""