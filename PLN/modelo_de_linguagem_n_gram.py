# -*- coding: utf-8 -*-
"""Cópia de Modelo de Linguagem N-Gram.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wDHF4gTPda59NNNyjoVhJLjeDmXdhRyY
"""

import random
import re
import requests
from collections import defaultdict, Counter
from bs4 import BeautifulSoup
import nltk
from nltk.util import bigrams

class NGramModel:
    def __init__(self, n):
        self.n = n  # Valor de n no modelo N-Grama (e.g., 1 para unigrama, 2 para bigrama)
        self.ngrams = defaultdict(Counter)  # Initializa um defaultdict de Counters para armazenar n-gramas e suas frequencias

    def train(self, text):
        tokens = self._tokenize(text)  # Tokeniza a entrada de texto
        ngrams = self._create_ngrams(tokens)  # Cria n-gramas a partir dos tokens

        for ngram in ngrams:  # Itera sobre as n-gramas criadas
            prefix, token = tuple(ngram[:-1]), ngram[-1]  # Separa a n-grama em prefixo e token
            self.ngrams[prefix][token] += 1  # Incrementa a frequencia do token que sucede o prefixo

    def train_char(self, text):
        tokens = self._tokenizeChar(text)  # Tokeniza a entrada de texto
        ngrams = self._create_ngrams(tokens)  # Cria n-gramas a partir dos tokens

        for ngram in ngrams:  # Itera sobre as n-gramas criadas
            prefix, token = tuple(ngram[:-1]), ngram[-1]  # Separa a n-grama em prefixo e token
            self.ngrams[prefix][token] += 1  # Incrementa a frequencia do token que sucede o prefixo

    def generate(self, max_words=100):
        output = []
        if self.n == 1:  # Tratando o caso de unigramas
            for _ in range(max_words):
                next_word = self._choose_next(None)  # Unigramas usam None como prefixo
                if next_word is None:
                    break
                output.append(next_word)
        else:
            current = random.choice(list(self.ngrams.keys()))  # Selecione um prefixo inicital aleatoriamente
            output = list(current)  # Inicializa a saída com o prefixo inicial

            for _ in range(max_words - self.n + 1):  # Gera palavras até que max_words seja alcançado
                next_word = self._choose_next(current)  # Escolhe a próxima palavra baseado no prefixo atual
                if next_word is None:  # Se nenhuma palvavra é encontrada, quebre o laço
                    break
                output.append(next_word)  # Adicione a próxima palavra à saída
                current = tuple(output[-self.n+1:])  # Atualize o prefixo atual

        return ' '.join(output)  # Retorna o texto gerado como string

    def _choose_next(self, prefix):
        if self.n == 1:
            options = self.ngrams[()]  # Para unigrama, use uma tupla vazia como chave
        else:
            options = self.ngrams.get(prefix, None)  # Pegue as possíveis próxijmas palavras para o dado prefixo

        if options:  # Se options foi encontrado
            total = sum(options.values())
            probs = [count / total for count in options.values()]  # Calcula as probabilidades
            return random.choices(list(options.keys()), weights=probs)[0]  # Escolha uma palavra baseada nas probabilidades
        else:
            return None  # Retorna None se options não for encontrado

    def _create_ngrams(self, tokens):
        if len(tokens) < self.n:
          return []
        return [tuple(tokens[i:i + self.n]) for i in range(len(tokens) - self.n + 1)]  # Create n-grams from tokens

    def _tokenizeChar(self, text):
        text = text.lower()  # Converte texto para caixa-baixa
        return [*text]  # Separa o texto em tokens

    def _tokenize(self, text):
        text = text.lower()  # Converte texto para caixa-baixa
        text = re.sub(r'\s+', ' ', text)  # Substitue múltiplos espaços com um único espaço
        text = re.sub(r'[^\w\s]', '', text)  # Remove pontuação
        return text.split()  # Separa o texto em tokens

# Function to read text from a file
def read_text_from_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

# Exemplo de uso



r = requests.get("https://www.gutenberg.org/cache/epub/29484/pg29484-images.html")

r.encoding = 'utf-8'

html = r.text

soup = BeautifulSoup(html, 'html.parser')

text = soup.get_text()

#file_path = 'sample_data/aRevolucao.txt'
#text = read_text_from_file(file_path)

unigram_model = NGramModel(1)
bigram_model = NGramModel(2)
trigram_model = NGramModel(3)

unigram_model.train(text)
bigram_model.train(text)
trigram_model.train(text)

print("Unigram Generated Text:", unigram_model.generate(max_words=10))
print("Bigram Generated Text:", bigram_model.generate(max_words=10))
print("Trigram Generated Text:", trigram_model.generate(max_words=10))

unigram_model.train_char(text)
bigram_model.train_char(text)
trigram_model.train_char(text)

print("Unigram Generated Text:", unigram_model.generate(max_words=10))
print("Bigram Generated Text:", bigram_model.generate(max_words=10))
print("Trigram Generated Text:", trigram_model.generate(max_words=10))

print(unigram_model.generate(max_words=100))



"""1 -  Rodei

2 - Trigrama teve um resultado melhor. Parece que por ser maior, consegue manter um significado maior

3 - O terceiro. Consegue manter um significado maior em comparação aos outros dois, creio quue por ele ser maior

"""